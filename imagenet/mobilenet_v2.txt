=> creating model 'mobilenet_v2'
=> Dummy data is used!
module.features.0.0.weight torch.Size([32, 3, 3, 3])
module.features.0.1.weight torch.Size([32])
module.features.0.1.bias torch.Size([32])
module.features.1.conv.0.0.weight torch.Size([32, 1, 3, 3])
module.features.1.conv.0.1.weight torch.Size([32])
module.features.1.conv.0.1.bias torch.Size([32])
module.features.1.conv.1.weight torch.Size([16, 32, 1, 1])
module.features.1.conv.2.weight torch.Size([16])
module.features.1.conv.2.bias torch.Size([16])
module.features.2.conv.0.0.weight torch.Size([96, 16, 1, 1])
module.features.2.conv.0.1.weight torch.Size([96])
module.features.2.conv.0.1.bias torch.Size([96])
module.features.2.conv.1.0.weight torch.Size([96, 1, 3, 3])
module.features.2.conv.1.1.weight torch.Size([96])
module.features.2.conv.1.1.bias torch.Size([96])
module.features.2.conv.2.weight torch.Size([24, 96, 1, 1])
module.features.2.conv.3.weight torch.Size([24])
module.features.2.conv.3.bias torch.Size([24])
module.features.3.conv.0.0.weight torch.Size([144, 24, 1, 1])
module.features.3.conv.0.1.weight torch.Size([144])
module.features.3.conv.0.1.bias torch.Size([144])
module.features.3.conv.1.0.weight torch.Size([144, 1, 3, 3])
module.features.3.conv.1.1.weight torch.Size([144])
module.features.3.conv.1.1.bias torch.Size([144])
module.features.3.conv.2.weight torch.Size([24, 144, 1, 1])
module.features.3.conv.3.weight torch.Size([24])
module.features.3.conv.3.bias torch.Size([24])
module.features.4.conv.0.0.weight torch.Size([144, 24, 1, 1])
module.features.4.conv.0.1.weight torch.Size([144])
module.features.4.conv.0.1.bias torch.Size([144])
module.features.4.conv.1.0.weight torch.Size([144, 1, 3, 3])
module.features.4.conv.1.1.weight torch.Size([144])
module.features.4.conv.1.1.bias torch.Size([144])
module.features.4.conv.2.weight torch.Size([32, 144, 1, 1])
module.features.4.conv.3.weight torch.Size([32])
module.features.4.conv.3.bias torch.Size([32])
module.features.5.conv.0.0.weight torch.Size([192, 32, 1, 1])
module.features.5.conv.0.1.weight torch.Size([192])
module.features.5.conv.0.1.bias torch.Size([192])
module.features.5.conv.1.0.weight torch.Size([192, 1, 3, 3])
module.features.5.conv.1.1.weight torch.Size([192])
module.features.5.conv.1.1.bias torch.Size([192])
module.features.5.conv.2.weight torch.Size([32, 192, 1, 1])
module.features.5.conv.3.weight torch.Size([32])
module.features.5.conv.3.bias torch.Size([32])
module.features.6.conv.0.0.weight torch.Size([192, 32, 1, 1])
module.features.6.conv.0.1.weight torch.Size([192])
module.features.6.conv.0.1.bias torch.Size([192])
module.features.6.conv.1.0.weight torch.Size([192, 1, 3, 3])
module.features.6.conv.1.1.weight torch.Size([192])
module.features.6.conv.1.1.bias torch.Size([192])
module.features.6.conv.2.weight torch.Size([32, 192, 1, 1])
module.features.6.conv.3.weight torch.Size([32])
module.features.6.conv.3.bias torch.Size([32])
module.features.7.conv.0.0.weight torch.Size([192, 32, 1, 1])
module.features.7.conv.0.1.weight torch.Size([192])
module.features.7.conv.0.1.bias torch.Size([192])
module.features.7.conv.1.0.weight torch.Size([192, 1, 3, 3])
module.features.7.conv.1.1.weight torch.Size([192])
module.features.7.conv.1.1.bias torch.Size([192])
module.features.7.conv.2.weight torch.Size([64, 192, 1, 1])
module.features.7.conv.3.weight torch.Size([64])
module.features.7.conv.3.bias torch.Size([64])
module.features.8.conv.0.0.weight torch.Size([384, 64, 1, 1])
module.features.8.conv.0.1.weight torch.Size([384])
module.features.8.conv.0.1.bias torch.Size([384])
module.features.8.conv.1.0.weight torch.Size([384, 1, 3, 3])
module.features.8.conv.1.1.weight torch.Size([384])
module.features.8.conv.1.1.bias torch.Size([384])
module.features.8.conv.2.weight torch.Size([64, 384, 1, 1])
module.features.8.conv.3.weight torch.Size([64])
module.features.8.conv.3.bias torch.Size([64])
module.features.9.conv.0.0.weight torch.Size([384, 64, 1, 1])
module.features.9.conv.0.1.weight torch.Size([384])
module.features.9.conv.0.1.bias torch.Size([384])
module.features.9.conv.1.0.weight torch.Size([384, 1, 3, 3])
module.features.9.conv.1.1.weight torch.Size([384])
module.features.9.conv.1.1.bias torch.Size([384])
module.features.9.conv.2.weight torch.Size([64, 384, 1, 1])
module.features.9.conv.3.weight torch.Size([64])
module.features.9.conv.3.bias torch.Size([64])
module.features.10.conv.0.0.weight torch.Size([384, 64, 1, 1])
module.features.10.conv.0.1.weight torch.Size([384])
module.features.10.conv.0.1.bias torch.Size([384])
module.features.10.conv.1.0.weight torch.Size([384, 1, 3, 3])
module.features.10.conv.1.1.weight torch.Size([384])
module.features.10.conv.1.1.bias torch.Size([384])
module.features.10.conv.2.weight torch.Size([64, 384, 1, 1])
module.features.10.conv.3.weight torch.Size([64])
module.features.10.conv.3.bias torch.Size([64])
module.features.11.conv.0.0.weight torch.Size([384, 64, 1, 1])
module.features.11.conv.0.1.weight torch.Size([384])
module.features.11.conv.0.1.bias torch.Size([384])
module.features.11.conv.1.0.weight torch.Size([384, 1, 3, 3])
module.features.11.conv.1.1.weight torch.Size([384])
module.features.11.conv.1.1.bias torch.Size([384])
module.features.11.conv.2.weight torch.Size([96, 384, 1, 1])
module.features.11.conv.3.weight torch.Size([96])
module.features.11.conv.3.bias torch.Size([96])
module.features.12.conv.0.0.weight torch.Size([576, 96, 1, 1])
module.features.12.conv.0.1.weight torch.Size([576])
module.features.12.conv.0.1.bias torch.Size([576])
module.features.12.conv.1.0.weight torch.Size([576, 1, 3, 3])
module.features.12.conv.1.1.weight torch.Size([576])
module.features.12.conv.1.1.bias torch.Size([576])
module.features.12.conv.2.weight torch.Size([96, 576, 1, 1])
module.features.12.conv.3.weight torch.Size([96])
module.features.12.conv.3.bias torch.Size([96])
module.features.13.conv.0.0.weight torch.Size([576, 96, 1, 1])
module.features.13.conv.0.1.weight torch.Size([576])
module.features.13.conv.0.1.bias torch.Size([576])
module.features.13.conv.1.0.weight torch.Size([576, 1, 3, 3])
module.features.13.conv.1.1.weight torch.Size([576])
module.features.13.conv.1.1.bias torch.Size([576])
module.features.13.conv.2.weight torch.Size([96, 576, 1, 1])
module.features.13.conv.3.weight torch.Size([96])
module.features.13.conv.3.bias torch.Size([96])
module.features.14.conv.0.0.weight torch.Size([576, 96, 1, 1])
module.features.14.conv.0.1.weight torch.Size([576])
module.features.14.conv.0.1.bias torch.Size([576])
module.features.14.conv.1.0.weight torch.Size([576, 1, 3, 3])
module.features.14.conv.1.1.weight torch.Size([576])
module.features.14.conv.1.1.bias torch.Size([576])
module.features.14.conv.2.weight torch.Size([160, 576, 1, 1])
module.features.14.conv.3.weight torch.Size([160])
module.features.14.conv.3.bias torch.Size([160])
module.features.15.conv.0.0.weight torch.Size([960, 160, 1, 1])
module.features.15.conv.0.1.weight torch.Size([960])
module.features.15.conv.0.1.bias torch.Size([960])
module.features.15.conv.1.0.weight torch.Size([960, 1, 3, 3])
module.features.15.conv.1.1.weight torch.Size([960])
module.features.15.conv.1.1.bias torch.Size([960])
module.features.15.conv.2.weight torch.Size([160, 960, 1, 1])
module.features.15.conv.3.weight torch.Size([160])
module.features.15.conv.3.bias torch.Size([160])
module.features.16.conv.0.0.weight torch.Size([960, 160, 1, 1])
module.features.16.conv.0.1.weight torch.Size([960])
module.features.16.conv.0.1.bias torch.Size([960])
module.features.16.conv.1.0.weight torch.Size([960, 1, 3, 3])
module.features.16.conv.1.1.weight torch.Size([960])
module.features.16.conv.1.1.bias torch.Size([960])
module.features.16.conv.2.weight torch.Size([160, 960, 1, 1])
module.features.16.conv.3.weight torch.Size([160])
module.features.16.conv.3.bias torch.Size([160])
module.features.17.conv.0.0.weight torch.Size([960, 160, 1, 1])
module.features.17.conv.0.1.weight torch.Size([960])
module.features.17.conv.0.1.bias torch.Size([960])
module.features.17.conv.1.0.weight torch.Size([960, 1, 3, 3])
module.features.17.conv.1.1.weight torch.Size([960])
module.features.17.conv.1.1.bias torch.Size([960])
module.features.17.conv.2.weight torch.Size([320, 960, 1, 1])
module.features.17.conv.3.weight torch.Size([320])
module.features.17.conv.3.bias torch.Size([320])
module.features.18.0.weight torch.Size([1280, 320, 1, 1])
module.features.18.1.weight torch.Size([1280])
module.features.18.1.bias torch.Size([1280])
module.classifier.1.weight torch.Size([1000, 1280])
module.classifier.1.bias torch.Size([1000])
VE: model DataParallel(
  (module): MobileNetV2(
    (features): Sequential(
      (0): Conv2dNormActivation(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
      (1): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): InvertedResidual(
        (conv): Sequential(
          (0): Conv2dNormActivation(
            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (1): Conv2dNormActivation(
            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU6(inplace=True)
          )
          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): Conv2dNormActivation(
        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
    )
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=1280, out_features=1000, bias=True)
    )
  )
)
module.features.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 3, 224, 224]) : torch.Size([256, 32, 112, 112])
module.features.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 32, 112, 112])
module.features.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 32, 112, 112])
module.features.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 3, 224, 224]) : torch.Size([256, 32, 112, 112])
module.features.1.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 32, 112, 112])
module.features.1.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 32, 112, 112])
module.features.1.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 32, 112, 112])
module.features.1.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 32, 112, 112])
module.features.1.conv.1: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 16, 112, 112])
module.features.1.conv.2: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 16, 112, 112]) : torch.Size([256, 16, 112, 112])
module.features.1.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 16, 112, 112])
module.features.1: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 16, 112, 112])
module.features.2.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 16, 112, 112]) : torch.Size([256, 96, 112, 112])
module.features.2.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 96, 112, 112]) : torch.Size([256, 96, 112, 112])
module.features.2.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 96, 112, 112]) : torch.Size([256, 96, 112, 112])
module.features.2.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 16, 112, 112]) : torch.Size([256, 96, 112, 112])
module.features.2.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 96, 112, 112]) : torch.Size([256, 96, 56, 56])
module.features.2.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 96, 56, 56]) : torch.Size([256, 96, 56, 56])
module.features.2.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 96, 56, 56]) : torch.Size([256, 96, 56, 56])
module.features.2.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 96, 112, 112]) : torch.Size([256, 96, 56, 56])
module.features.2.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 96, 56, 56]) : torch.Size([256, 24, 56, 56])
module.features.2.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 24, 56, 56])
module.features.2.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 16, 112, 112]) : torch.Size([256, 24, 56, 56])
module.features.2: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 16, 112, 112]) : torch.Size([256, 24, 56, 56])
module.features.3.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 24, 56, 56])
module.features.3.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 24, 56, 56])
module.features.3.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 24, 56, 56])
module.features.3: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 24, 56, 56])
module.features.4.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.4.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.4.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.4.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.4.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 28, 28])
module.features.4.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 144, 28, 28]) : torch.Size([256, 144, 28, 28])
module.features.4.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 144, 28, 28]) : torch.Size([256, 144, 28, 28])
module.features.4.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 28, 28])
module.features.4.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 144, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.4.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.4.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 32, 28, 28])
module.features.4: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 32, 28, 28])
module.features.5.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.5.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.5.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.5: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.6.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.6.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.6.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.6: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.7.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.7.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.7.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.7.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.7.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 14, 14])
module.features.7.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 192, 14, 14]) : torch.Size([256, 192, 14, 14])
module.features.7.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 192, 14, 14]) : torch.Size([256, 192, 14, 14])
module.features.7.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 14, 14])
module.features.7.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 192, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.7.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.7.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 64, 14, 14])
module.features.7: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 64, 14, 14])
module.features.8.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.8.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.8.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.8: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.9.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.9.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.9.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.9: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.10.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.10.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.10.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.10: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.11.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.11.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.11.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.11: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.12.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.12.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.12.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.12: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.13.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.13.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.13.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.13: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.14.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.14.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.14.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.14.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.14.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 7, 7])
module.features.14.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 576, 7, 7]) : torch.Size([256, 576, 7, 7])
module.features.14.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 576, 7, 7]) : torch.Size([256, 576, 7, 7])
module.features.14.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 7, 7])
module.features.14.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 576, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.14.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.14.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 160, 7, 7])
module.features.14: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 160, 7, 7])
module.features.15.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.15.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.15.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.15: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.16.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.16.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.16.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.16: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.17.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 320, 7, 7])
module.features.17.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 320, 7, 7]) : torch.Size([256, 320, 7, 7])
module.features.17.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 320, 7, 7])
module.features.17: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 320, 7, 7])
module.features.18.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 320, 7, 7]) : torch.Size([256, 1280, 7, 7])
module.features.18.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 1280, 7, 7]) : torch.Size([256, 1280, 7, 7])
module.features.18.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 1280, 7, 7]) : torch.Size([256, 1280, 7, 7])
module.features.18: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 320, 7, 7]) : torch.Size([256, 1280, 7, 7])
module.features: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 3, 224, 224]) : torch.Size([256, 1280, 7, 7])
module.classifier.0: <class 'torch.nn.modules.dropout.Dropout'> : torch.Size([256, 1280]) : torch.Size([256, 1280])
module.classifier.1: <class 'torch.nn.modules.linear.Linear'> : torch.Size([256, 1280]) : torch.Size([256, 1000])
module.classifier: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 1280]) : torch.Size([256, 1000])
module: <class 'torchvision.models.mobilenetv2.MobileNetV2'> : torch.Size([256, 3, 224, 224]) : torch.Size([256, 1000])
: <class 'torch.nn.parallel.data_parallel.DataParallel'> : torch.Size([256, 3, 224, 224]) : torch.Size([256, 1000])
Epoch: [0][   1/5005]	Time 21.059 (21.059)	Data  1.585 ( 1.585)	Loss 6.9389e+00 (6.9389e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.39 (  0.39)
module.features.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 3, 224, 224]) : torch.Size([256, 32, 112, 112])
module.features.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 32, 112, 112])
module.features.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 32, 112, 112])
module.features.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 3, 224, 224]) : torch.Size([256, 32, 112, 112])
module.features.1.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 32, 112, 112])
module.features.1.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 32, 112, 112])
module.features.1.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 32, 112, 112])
module.features.1.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 32, 112, 112])
module.features.1.conv.1: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 16, 112, 112])
module.features.1.conv.2: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 16, 112, 112]) : torch.Size([256, 16, 112, 112])
module.features.1.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 16, 112, 112])
module.features.1: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 32, 112, 112]) : torch.Size([256, 16, 112, 112])
module.features.2.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 16, 112, 112]) : torch.Size([256, 96, 112, 112])
module.features.2.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 96, 112, 112]) : torch.Size([256, 96, 112, 112])
module.features.2.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 96, 112, 112]) : torch.Size([256, 96, 112, 112])
module.features.2.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 16, 112, 112]) : torch.Size([256, 96, 112, 112])
module.features.2.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 96, 112, 112]) : torch.Size([256, 96, 56, 56])
module.features.2.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 96, 56, 56]) : torch.Size([256, 96, 56, 56])
module.features.2.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 96, 56, 56]) : torch.Size([256, 96, 56, 56])
module.features.2.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 96, 112, 112]) : torch.Size([256, 96, 56, 56])
module.features.2.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 96, 56, 56]) : torch.Size([256, 24, 56, 56])
module.features.2.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 24, 56, 56])
module.features.2.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 16, 112, 112]) : torch.Size([256, 24, 56, 56])
module.features.2: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 16, 112, 112]) : torch.Size([256, 24, 56, 56])
module.features.3.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.3.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 24, 56, 56])
module.features.3.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 24, 56, 56])
module.features.3.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 24, 56, 56])
module.features.3: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 24, 56, 56])
module.features.4.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.4.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.4.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.4.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 144, 56, 56])
module.features.4.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 28, 28])
module.features.4.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 144, 28, 28]) : torch.Size([256, 144, 28, 28])
module.features.4.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 144, 28, 28]) : torch.Size([256, 144, 28, 28])
module.features.4.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 144, 56, 56]) : torch.Size([256, 144, 28, 28])
module.features.4.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 144, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.4.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.4.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 32, 28, 28])
module.features.4: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 24, 56, 56]) : torch.Size([256, 32, 28, 28])
module.features.5.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.5.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.5.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.5.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.5: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.6.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.6.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.6.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.6.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.6: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 32, 28, 28])
module.features.7.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.7.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.7.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.7.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 192, 28, 28])
module.features.7.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 14, 14])
module.features.7.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 192, 14, 14]) : torch.Size([256, 192, 14, 14])
module.features.7.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 192, 14, 14]) : torch.Size([256, 192, 14, 14])
module.features.7.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 192, 28, 28]) : torch.Size([256, 192, 14, 14])
module.features.7.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 192, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.7.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.7.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 64, 14, 14])
module.features.7: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 32, 28, 28]) : torch.Size([256, 64, 14, 14])
module.features.8.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.8.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.8.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.8.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.8: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.9.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.9.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.9.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.9.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.9: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.10.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.10.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.10.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.10.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.10: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 64, 14, 14])
module.features.11.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 384, 14, 14])
module.features.11.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 384, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.11.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.11.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.11: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 64, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.12.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.12.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.12.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.12.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.12: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.13.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.13.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.13.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.13.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.13: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 96, 14, 14])
module.features.14.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.14.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.14.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.14.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 576, 14, 14])
module.features.14.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 7, 7])
module.features.14.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 576, 7, 7]) : torch.Size([256, 576, 7, 7])
module.features.14.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 576, 7, 7]) : torch.Size([256, 576, 7, 7])
module.features.14.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 576, 14, 14]) : torch.Size([256, 576, 7, 7])
module.features.14.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 576, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.14.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.14.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 160, 7, 7])
module.features.14: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 96, 14, 14]) : torch.Size([256, 160, 7, 7])
module.features.15.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.15.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.15.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.15.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.15: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.16.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.16.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.16.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.16.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.16: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 160, 7, 7])
module.features.17.conv.0.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.0.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.0.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.0: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.1.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.1.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.1.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.1: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 960, 7, 7])
module.features.17.conv.2: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 960, 7, 7]) : torch.Size([256, 320, 7, 7])
module.features.17.conv.3: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 320, 7, 7]) : torch.Size([256, 320, 7, 7])
module.features.17.conv: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 320, 7, 7])
module.features.17: <class 'torchvision.models.mobilenetv2.InvertedResidual'> : torch.Size([256, 160, 7, 7]) : torch.Size([256, 320, 7, 7])
module.features.18.0: <class 'torch.nn.modules.conv.Conv2d'> : torch.Size([256, 320, 7, 7]) : torch.Size([256, 1280, 7, 7])
module.features.18.1: <class 'torch.nn.modules.batchnorm.BatchNorm2d'> : torch.Size([256, 1280, 7, 7]) : torch.Size([256, 1280, 7, 7])
module.features.18.2: <class 'torch.nn.modules.activation.ReLU6'> : torch.Size([256, 1280, 7, 7]) : torch.Size([256, 1280, 7, 7])
module.features.18: <class 'torchvision.ops.misc.Conv2dNormActivation'> : torch.Size([256, 320, 7, 7]) : torch.Size([256, 1280, 7, 7])
module.features: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 3, 224, 224]) : torch.Size([256, 1280, 7, 7])
module.classifier.0: <class 'torch.nn.modules.dropout.Dropout'> : torch.Size([256, 1280]) : torch.Size([256, 1280])
module.classifier.1: <class 'torch.nn.modules.linear.Linear'> : torch.Size([256, 1280]) : torch.Size([256, 1000])
module.classifier: <class 'torch.nn.modules.container.Sequential'> : torch.Size([256, 1280]) : torch.Size([256, 1000])
module: <class 'torchvision.models.mobilenetv2.MobileNetV2'> : torch.Size([256, 3, 224, 224]) : torch.Size([256, 1000])
: <class 'torch.nn.parallel.data_parallel.DataParallel'> : torch.Size([256, 3, 224, 224]) : torch.Size([256, 1000])
Test: [  1/196]	Time  1.235 ( 1.235)	Loss 6.9086e+00 (6.9086e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
 *   Acc@1 0.000 Acc@5 0.000
